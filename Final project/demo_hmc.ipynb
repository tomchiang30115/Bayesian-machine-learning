{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Demonstration of Hamiltonian Monte Carlo (HMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T16:42:16.889266Z",
     "start_time": "2022-04-05T16:42:16.641929Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hmc_Lab as hmc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"Distribution\"\n",
    "\n",
    "The distribution used here is a contrived two-dimensional one, but un-normalised.\n",
    "That is, it is in the form $P^\\ast(x_1, x_2)$.\n",
    "\n",
    "To run HMC, we must define the \"energy\" and gradient functions first.\n",
    "- `energy_func`: the energy function is $-\\log P^\\ast(x_1, x_2)$,\n",
    "- `energy_grad`: the gradient function returns an array containing\n",
    "the partial derivatives of the energy function with respect to the parameters,\n",
    "which are $x_1$ and $x_2$ here,\n",
    "- this may take a little bit of working out,\n",
    "- it is always worth checking for errors by using the `checkgrad` functionality\n",
    "(demonstrated below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Error Function\n",
    "This is the negative log-probability of our un-normalised distribution. This example here\n",
    "is entirely artificial. It is Gaussian in one axis, and Gaussian modulated by a harmonic\n",
    "function in the other.\n",
    "\n",
    "Remember that energy is *negative* log probability, hence the negated return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T15:44:22.864925Z",
     "start_time": "2022-04-05T15:44:22.862412Z"
    }
   },
   "outputs": [],
   "source": [
    "def energy_func(x, f):\n",
    "    # Simulating some unknown log-probability\n",
    "    p0 = -x[0]**2/2\n",
    "    p1 = -x[1]**2/2 + np.log(2+np.cos(f*x[1]))\n",
    "    lgp = p0 + p1\n",
    "    return -lgp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gradient Function\n",
    "This an array containing the partial derivatives of the energy function with respect to\n",
    "$x_1$ and $x_2$. It generally will need to be worked out by hand. In this case, `g[0]`\n",
    "is trivial, while `g[1]` needed application of the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T15:44:24.979000Z",
     "start_time": "2022-04-05T15:44:24.976516Z"
    }
   },
   "outputs": [],
   "source": [
    "def energy_grad(x, f):\n",
    "    g = np.empty(2)\n",
    "    g[0] = x[0]\n",
    "    g[1] = x[1] + f*np.sin(f*x[1]) / (2+np.cos(f*x[1]))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the Distribution\n",
    "Before we run the sampler, let's visualise the distribution over an appropriate\n",
    "grid of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T15:44:26.629176Z",
     "start_time": "2022-04-05T15:44:26.418082Z"
    }
   },
   "outputs": [],
   "source": [
    "f = 5  # The \"frequency\" argument for the energy, used here to demonstrate use of \"args\"\n",
    "# Plotting parameters\n",
    "fsz = (10,8)\n",
    "gsz = 100\n",
    "lim = 3\n",
    "#\n",
    "gx = np.linspace(-lim, lim, gsz)\n",
    "GX, GY = np.meshgrid(gx, gx)\n",
    "Gsz = GX.size\n",
    "G = np.hstack((GX.reshape((Gsz, 1)), GY.reshape((Gsz, 1))))\n",
    "#\n",
    "plt.figure(figsize=fsz)\n",
    "P = np.asarray([np.exp(-energy_func(g, f)) for g in G])\n",
    "plt.contour(GX, GY, P.reshape((gsz, gsz)), cmap='Reds', linewidths=3, zorder=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Sampler\n",
    "\n",
    "First, to run the sampler we must pass in the energy and gradient functions as defined above.\n",
    "\n",
    "As well as `x` which is to be sampled, those functions need the \"frequency\" parameter `f`\n",
    "(which is fixed). This is passed as `args` to the sampler (and subsequently forwarded\n",
    "internally to `energy_func` and `energy_grad`). When sampling in Bayesian regression contexts,\n",
    "you will need to pass the data set there. *e.g.* `args = [x_train, t_train]`.\n",
    "\n",
    "Additionally, there are some further arguments we must specify:\n",
    "\n",
    "- `R`: the number of samples desired\n",
    "- `L`: number of simulation steps; for this simple case, 20 is easily enough\n",
    "- `eps`: simulation step length; set by trial-and-error to give approx. 90% acceptance\n",
    "- `burn`: simply set to `R/10`\n",
    "- `checkgrad`: set to true to test the consistency of `e_func` and `e_grad`\n",
    "\n",
    "In summary: with `L` chosen roughly in accordance with the complexity of the distribution,\n",
    "only `eps` really needs to be adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Check\n",
    "In this example, to demonstrate it more clearly, we run the gradient check separately\n",
    "in advance (you would normally want to do it automatically in `sample`).\n",
    "\n",
    "Running `gradient_check` below will calculate a numerical estimate of the gradient\n",
    "(using `energy_func`) and compare it with the analytic value (from `energy_grad`) for each parameter\n",
    "individually. Because it is\n",
    "a numerical estimate, there will always be a small discrepancy, but if this becomes large,\n",
    "it likely indicates some error.\n",
    "\n",
    "The most informative column in the output below is probably `Acc.`,\n",
    "which gives a logarithmic (base-10)\n",
    "measure of relative accuracy. For example, an accuracy of \"9\" implies\n",
    "an error less than one part in $10^9$. Anything lower than 6 might indicate a minor error\n",
    "(in maths and/or code), and anything less than 4 almost certainly does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T15:44:29.064376Z",
     "start_time": "2022-04-05T15:44:29.061637Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Initial state: something random and sensible\n",
    "x0 = np.random.normal(size=2)\n",
    "hmc.gradient_check(x0, energy_func, energy_grad, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Sampler!\n",
    "\n",
    "At every `R/10` steps (plus after burn-in), the sampler indicates the progress so far\n",
    "along with the cumulative acceptance rate to that point. The sampler parameters are\n",
    "also summarised at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T15:44:32.811328Z",
     "start_time": "2022-04-05T15:44:30.216732Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "np.random.seed(seed=1)  # For reproducibility\n",
    "R = 10000  # More than really needed, but produces a nice dense plot\n",
    "burn = int(R/10)  # A reasonable rule-of-thumb\n",
    "L = 20  # OK here (should be larger in regression sampling)\n",
    "eps = 0.3  # Trial-and-error ... feel free to experiment!\n",
    "#\n",
    "S, *_ = hmc.sample(x0, energy_func, energy_grad, R, L, eps, burn=burn, checkgrad=False, args=[f])\n",
    "#\n",
    "plt.figure(figsize=fsz)\n",
    "plt.plot(S[:, 0], S[:, 1], '.', ms=6, color='CadetBlue', alpha=0.25, zorder=0)\n",
    "plt.contour(GX, GY, P.reshape((gsz, gsz)), cmap='Reds', linewidths=3, zorder=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
